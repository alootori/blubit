import pandas as pd
import re
import torch
from sentence_transformers import SentenceTransformer, util

from tqdm import tqdm


# Load Sentence Transformer Model (Optimized for GPU)
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

model = SentenceTransformer("intfloat/e5-large").to(device)  # Best for retrieval & similarity

# Define multiple reference queries (to handle different phrasings)
reference_queries = [
    ""
]

# Encode all reference queries (Move to GPU for faster computation)
query_embeddings = {query: model.encode(query, convert_to_tensor=True, device=device) for query in reference_queries}

# Load  dataset into a Pandas DataFrame
df = pd.read_csv("data.csv")

# Function to split text into sentences
def split_text(text):
    if pd.isna(text): return []

    # First split by newline (\n), then by period (.)
    sentences = []
    for part in text.split("\n"):
        sentences.extend(re.split(r'\.\s*', part))  # Split by period with optional spaces

    sentences = [s.strip() for s in sentences if len(s.strip()) > 5]  # Remove empty/short fragments
    return sentences

# Function to find max similarity & best matching sentence
def find_max_similarity(sentences):
    max_similarity = 0
    best_sentence = ""
    best_query = ""

    for sentence in sentences:
        sentence_embedding = model.encode(sentence, convert_to_tensor=True, device=device)

        for query, query_embedding in query_embeddings.items():
            similarity_score = util.cos_sim(query_embedding, sentence_embedding).item()

            if similarity_score > max_similarity:
                max_similarity = similarity_score
                best_sentence = sentence
                best_query = query  # Store best-matching reference query

    return max_similarity, best_sentence, best_query

# Apply sentence processing & similarity computation in batches
df["sentences"] = df["desc"].apply(split_text)
df[["max_similarity", "best_sentence", "best_query"]] = df["sentences"].apply(lambda x: find_max_similarity(x) if x else (0, "", ""))

# Suggest an optimal threshold based on 90th percentile
threshold = max(0.85, df["max_similarity"].quantile(0.90))
print(f"ðŸ”¹ Suggested Optimal Threshold: {threshold:.2f}")

# Apply threshold & flag 
df["flagged"] = df["max_similarity"] >= threshold



# Display flagged 
import ace_tools as tools
tools.display_dataframe_to_user(name="Flagged", dataframe=df[df["flagged"]])
