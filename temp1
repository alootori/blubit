import re
import string

def classify_call_note_with_llama(text):
    """
    Uses the Llama model to classify a call note.
    The prompt instructs the model to respond in a strict format:
      Yes|||<one-sentence explanation>
    or simply:
      No
    This function removes any repeated prompt and robustly parses the answer,
    stripping punctuation from the first token to decide.
    """
    prompt = (
        "Please classify the following customer call note. "
        "If the customer actively requested to withdraw or close their claim, "
        "reply EXACTLY in the following format (with no additional text):\n"
        "Yes|||<one-sentence explanation>\n"
        "If not, simply reply with:\n"
        "No\n\n"
        "Call Note:\n\"\"\"\n" + text + "\n\"\"\"\n\nAnswer:"
    )
    
    # Generate output from the model with a controlled number of new tokens.
    full_output = llama_pipeline(prompt, max_new_tokens=100, do_sample=False)[0]['generated_text']
    
    # Remove the prompt portion if it is repeated in the output.
    if full_output.startswith(prompt):
        answer_text = full_output[len(prompt):].strip()
    else:
        answer_text = full_output.strip()
    
    # Debug print (optional)
    # print("Raw Answer Text:", answer_text)
    
    # Check if the output contains our delimiter.
    if "|||" in answer_text:
        parts = answer_text.split("|||", 1)
        raw_decision = parts[0].strip()
        explanation = parts[1].strip()
    else:
        # Fallback: take the first word as the decision.
        tokens = answer_text.split()
        raw_decision = tokens[0] if tokens else ""
        explanation = ""
    
    # Remove punctuation and extra spaces from the decision token.
    decision_token = raw_decision.strip(string.punctuation + " ").lower()
    decision = "Yes" if decision_token.startswith("yes") else "No"
    
    return decision, explanation, full_output

# Example usage:
sample_text = "The customer called and clearly requested to withdraw their claim immediately."
decision, explanation, full_output = classify_call_note_with_llama(sample_text)
print("Decision:", decision)
print("Explanation:", explanation)
print("Full Model Output:", full_output)
